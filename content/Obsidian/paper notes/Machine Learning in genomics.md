# Revisiting genome-wide association studies from statistical modelling to machine learning (2020)
## Intro
Over the last decade, genome-wide association studies (GWAS) have discovered thousands of genetic variants underlying complex human diseases and agriculturally important traits. These findings have been utilized to dissect the biological basis of diseases, to develop new drugs, to advance precision medicine and to boost breeding. However, the potential of GWAS is still underexploited due to methodological limitations. Many challenges have emerged, including detecting epistasis and single-nucleotide polymorphisms (SNPs) with *small effects* and distinguishing causal variants from other SNPs associated through *linkage disequilibrium*. These issues have motivated advancements in GWAS analyses in two contrasting cultures—*statistical modelling* and *machine learning*. In this review, we systematically present the basic concepts and the benefits and limitations in both methods. We further discuss recent efforts to mitigate their weaknesses. Additionally, we summarize the state-of-the-art tools for detecting the missed signals, ultrarare mutations and gene–gene interactions and for prioritizing SNPs. Our work can offer both theoretical and practical guidelines for performing GWAS analyses and for developing further new robust methods to fully exploit the potential of GWAS. 

Identifying causal genes underlying diseases and traits of interests is one of the key tasks of molecular studies. Various methods have been used to pinpoint the genetic variation leading to trait variation and trait correlations [1]. Among them, genomewide association studies (GWAS) have gained in popularity over past decades because of the decreasing price ofhigh-throughput sequencing (∼40$ per sample) [2, 3]. Specifically, GWAS test the genetic variants (usually single-nucleotide polymorphisms, SNPs) across genomes from many individuals [4]. They require no prior knowledge about the causal genes, such as the gene functions and their locations on the genome [1]. More importantly, they can be used to study low-frequency and rare variants [5]. The *first* study of true *GWAS* designed for a complex disease was published in *2007* [6]. Since then approximately 185 864  GWAS associations have been accumulated for human [7] and 75 467 for agriculturally important plants and animals [8]. These studies provide important information to dissect the biological basis underlying diseases [9], to develop new drugs [10], to advance precision medicine [11] and to boost breeding [12–14]. For example, GWAS have been used to identify the potential causal genes and biological processes that are involved in type 2 diabetes, autoimmune diseases and schizophrenia [15]. These results were later successfully translated to candidate drugs and new drugs [15]. For breeding practices, new functional alleles identified by GWAS have been used as the basis for genomic selection to predict the breeding value of the offspring [16, 17] and for revealing genes that affect the production and the quality of crops, such as soybean [18–20]. These examples all clearly demonstrate the success of GWAS in delivering its original aim of  identifying genotype–phenotype associations and, beyond this, in dissecting the genetic and biological architecture of complex traits [2, 15]. 

The age and achievements of GWAS may show the maturity [15]. However, technologies of GWAS, especially analysis methods, are still evolving. Traditional analyses rely mostly on *statistical modelling*, i.e. a series of single-SNP tests that independently test *each SNP* for the *genotype–phenotype associations* [21]. This method is being criticized as causing the *‘missing heritability’,* the fact that a large number of variants identified by GWAS only account for a modest proportion of the heritability of complex traits [22, 23]. One explanation is that the corrections for multiple tests exclude relevant SNPs with *small effects* [24]. A typical GWAS using SNP arrays can involve 200 000–2 000 000 SNPs [15]. The huge volume of significance tests for individual SNPs can lead to random events being falsely significant. Therefore, the single-SNP tests need stricter P-values (usually 5 × 10^6 – 5 × 10^8 ) to minimize the occurrence of false positives [21, 25]. However, if the effect of individual causal SNPs is too small, they can fail to pass the stringent significance thresholds [24]. Another explanation is that causal genetic *interactions* (i.e. *epistasis*) are often ignored in GWAS because of methodological challenges [26, 27]. Another criticism for the single-SNP tests is that the one-SNP-at-a-time analysis *disregards the correlations among the tested SNPs*. Thus, distinguishing causal genes from other genes associated through *linkage disequilibrium* (LD) is difficult, complicating the prioritization of candidate variants for further studies [28–30]. These limitations motivate recent advancements in statistical modelling and, more importantly, the application of machine learning methods in GWAS [2].
	- Epistasis is a type of genetic interaction between two or more genes, where the effect of one gene on a particular trait is dependent on the presence of one or more other genes. In other words, epistasis occurs when the effect of a gene on a phenotype is modified by the presence or absence of other genes.

*Machine learning*, in contrast to statistical modelling, is a *statistic-free method*. It does *not need* to specify the *distribution of the population* investigated, to assess the estimators (confidence intervals and P-values) or to test the null hypotheses, thus being *free from multi-testing issue* [31]. Moreover, machine learning is *more robust to* detect SNPs with *small effects* by evaluating simultaneously pan-genomic SNPs [27]. It has shown higher statistical power and precision to identify the candidate SNPs [29, 32] and high orders of epistasis [33–36]. Machine learning has also been used to prioritize genes for follow-up GWAS laboratory studies [37–39]. For example, Vitsios and Petrovski [37] used machine learning to rank disease-associated genes and found that the top-ranked genes well captured the true prioritization signals. These results suggest the fitness and power of machine learning for GWAS. However, machine learning also suffers some criticisms, such as its *low interpretability*, which lead to that many bioscientists are skeptical about machine learning [40, 41].

In this review, we outline the basic concepts and key steps in applying statistical modelling and machine learning in GWAS. We also survey the benefits and limitations in each method and recent advancements to mitigate their weaknesses. These efforts can help researchers become familiar with the state-of- the-art methods and confident with their analyses and may also contribute to further design of robust analysis methods to fully exploit the potential of GWAS.

## Statistical Modeling
### Single-SNP test
Traditional single-SNP tests need to predefine a genetic model to facilitate comparisons of inheritance effects of genotypes [42]. For example, let A be the mutant allele (i.e. the susceptibility allele) and G be the wild-type allele from a biallelic locus. A *dominant model* will reduce the comparisons among GG, GA and AA to between AA + GA and GG; a *recessive model* will compare AA with GA + GG; a co-dominant or *additive model* will place GA in between GG and AA [21]. Different models can lead to differences in GWAS results [43]. A general recommendation for the choice of genetic models is *first* to screen the SNPs using the *co-dominant model* and *then* to perform association test using *all genetic models with significant SNPs* [21]. Once a genetic *model is selected*, various *statistical tests* can be used for the *single-SNP* tests, including *chi-squared test*, *odds ratio test*, *Fisher’s exact test*, *Cochran–Armitage’s trend test*, analysis of variance (*ANOVA*) and *t-test*. 
	Cochran-Armitage's trend test（科克伦-阿米特奇趋势检验）是一种常见的统计方法，用于研究两个分类变量之间的趋势关系。该方法主要用于分析二元变量（例如，存在或不存在某种疾病），并且可以用于评估该变量在一个或多个因素中的趋势变化。例如，可以使用该方法评估年龄、性别或其他因素对某种疾病的发病率的影响。Cochran-Armitage's trend test基于一个假设，即当一个因素对变量的值有影响时，该变量的值在不同组之间呈线性趋势变化。该测试统计每个组中变量的频率，并根据每个组的大小对变量的线性趋势进行评估。Cochran-Armitage's trend test可用于分析2x2表或更大的表格，可以检查各组之间的差异是否趋于线性。该方法的优点在于，它不需要假设任何特定的分布形式，而且在数据中存在缺失值的情况下仍然有效。

Chi-squared test evaluates the significance of the deviation of the observed allele/genotypes counts from the expected counts in a contingency table. The odds ratio test assesses the effect sizes of mutating genotypes or mutating alleles by comparing their odds. Fisher’s exact test is similar to chi-squared test but is more accurate when the sample size is small. *Cochran–Armitage’s trend test* incorporates assumed ordinal effects of the genotypes into the chi-squared test [44]. This method has been found to be *more powerful than chi-squared test* when SNPs *deviate* from *Hardy–Weinberg equilibrium* due to such as population stratification [45]. When a quantitative phenotype is investigated, t-test and ANOVA can be used to test the significance of differences between alleles and between genotypes, respectively. However, as the structure of the SNP increases from being biallelic to triallelic and quadallelic, as in some microorganisms, the benefits of a prior genetic model will be minor.
	Hardy-Weinberg平衡是一种基本的遗传学原理，描述了在一定条件下，基因型频率的分布将保持不变。具体来说，Hardy-Weinberg平衡描述了在不存在演化、选择、迁移和突变等影响的情况下，基因型频率的分布会保持不变。在这种情况下，一个群体中各个基因型的频率将取决于等位基因频率的分布，而不受基因型的影响。p² + 2pq + q² = 1 其中，p表示等位基因A的频率，q表示等位基因a的频率，p²表示AA基因型频率，2pq表示Aa基因型频率，q²表示aa基因型频率，且p²+2pq+q²=1表示基因型频率总和为1。Hardy-Weinberg平衡是理论上的一个理想情况，但在现实中很难完全实现。因为演化、选择、迁移和突变等因素会对基因型频率的分布产生影响。在实践中，Hardy-Weinberg平衡通常用于检验一个群体的基因型分布是否符合理论预期，并用于研究基因的遗传方式和种群遗传学的基本原理。

*Linear models* can be used to perform the single-SNP tests without specifying a genetic model. The inheritance effects of genotypes can be tested afterwards if a significant association is found. The simplest form of a statistical linear model is as follows: ![[Pasted image 20230412195657.png|100]] where y is the dependent variable, x is the independent variable, β0 is the intercept, β1 is the slope and ε is a random error com- ponent with ε ∼ (0, σ 2 ). In GWAS, the quantitative or qualitative *phenotype* of interest will be *y* and the *SNP* tested will be *x* but encoded as n − 1 *dummy* variables, with n being the number of genotypes. For example, for a biallelic SNP (G and A, see above), as encoded in Figure 1, Equation (1) can be rewritten as: ![[Pasted image 20230412195844.png|120]] where β0 is the intercept that integrates the effect of GG on the phenotype, β1 is the effect that mutates GG to GA, β2 is the effect that mutates GG to AA and ε is the residual effect. The effect of mutating GA to AA can be assessed based on the difference between β2 and β1 (i.e. β2 − β1). Thus, the existence of significant β1 and β2 and insignificant β2 − β1 indicates a dominant model, while the significant β2 and β2 − β1 and insignificant β1 represent a recessive model. When β1, β2 and their difference are all significant, a co-dominant or additive model is found. Equation (2) can be expressed in a matrix form as follows: ![[Pasted image 20230412195930.png|70]] where Y is a vector of phenotypes of interest, X is a vector of genotypes with their corresponding effect estimators β and ε is a vector of residual effects. β can be estimated using the ordinary least squares (OLS) that is the solution to the optimization problem. ![[Pasted image 20230412200050.png|100]] The *significant* difference between *β*ˆOLS and 0 that passes a certain stringent threshold indicates that the causal SNP or SNP in LD with the causal variant is found. The framework of linear models can easily incorporate covariates that may influence the phenotype, such as age, sex and environmental exposures. Equation (3) can be rewritten as: ![[Pasted image 20230412200158.png|100]] where Y is a vector of phenotypes of interest, X is a vector of genotypes with their corresponding effect estimators β, W is a vector of fixed covariates with their corresponding effect estimators u and ε is a vector of residual effects. Further, biases due to the population stratification, family structure and cryptic relatedness that represent systematic genetic differences between controls and cases can also be handled with linear models. Equation (5) can be rewritten as: ![[Pasted image 20230412200335.png|100]] where *g* is a vector of the *heritable components* that can be estimated based on the genotypic similarities between pairwise individuals and is treated as *random effects*, while X and W are the same as in Equation (5) and treated as fixed effects. Including covariates and systematic genetic differences can remove spurious associations caused by biases in study design and sampling errors; however, it may reduce the statistical power by consuming additional degrees of freedom.
### Multi-SNP test
Complex phenotypes are often influenced by a group of alleles [46]. Single-SNP test fails to capture the joint effects of multiple SNPs; therefore, multi-SNP association test is ideally preferred. However, multi-SNP test is troubled with the ‘*large p, small n*’ problem; that is, the *number of SNPs exceeds the number of samples*/individuals, thus making the estimation of model parameters difficult. Possible solutions are using the *SNP tagging* followed with a f*orward stepwise selection procedure* or using the *penalized regression or Bayesian* approaches.

**SNP tagging** is a procedure to select a *representative subset of SNPs* (i.e. tag SNPs) that retains the maximum genetic infor- mation from the full SNP set based on the facts that SNPs are in LD and thus many of them contain overlapped or even the same information. Various methods have been proposed mostly based on the LD level between two SNPs. However, the tagging *consistency* between different methods is *poor*, and thus, the selection of methods needs careful consideration [47]. After the tag SNPs are identified, the forward stepwise selection starts. The *tag SNPs are incrementally added to the linear model*. The SNP is removed from the model if its inclusion does not improve model performances according to some measures, such as adjusted R2 , Akaike information criterion and Bayesian information criterion. The SNPs in the final model are identified as significant and relevant. A drawback for the forward stepwise selection is that the model is usually *overfitted* [48], and the estimate of *heritability explained by* the final set of *SNPs* is *biased high*. The *penalized regression* adds a penalty or regularization term to the linear model and shrinks the coefficients of irrelevant SNPs towards zero as shown in Equation (7). ![[Pasted image 20230412201509.png|200]] where λP(β ) is the penalty term. When λ = 0, the estimation of βˆ is based on the OLS (see Equation 4). As λ increases, high penalty is imposed on the model complexity (i.e. the number of SNPs). The estimation of parameters needs to balance model complexity and goodness of fit to avoid overfitting *using training and validation datasets*. The latter two concepts belong to machine learning. Thus, commonly used *penalized regressions*, such as ridge regression, LASSO and elastic net, are categorized as *machine learning methods*. Overall, penalized regressions *need large sample sizes* to achieve good performances [49].

*Bayesian* methods, such as Bayesian variable selection [50– 52] and Bayesian penalized regressions [53, 54], most recently have been used as a promising alternative to assess the joint effect of multiple SNPs. A large advantage of these methods is *freedom from the multiple testing* problem and thus can be sensitive to SNPs with small effect sizes [55]. For example, Zhao et al. [52] developed a hierarchical variable selection method based on the Bayesian framework and found that their new method identified more biologically meaningful genes than single-SNP tests. *However*, Bayesian approaches are usually *computationally costly*. Novel methodologies with high computation efficiency may boost the application of Bayesian methods in GWAS. Another thing to note for Bayesian methods is that the implementation of Bayesian framework *requires* researchers to explicitly *make prior specifications* about the probability of the SNP that is associated with the phenotype of interest and about the distribution of its effect size [55]. These specifications are *subjective* and often influence the associations that are identified [55].

### Epistasis identification
Epistasis generally refers to a phenomenon, where the effect of a set of two or more genes on a phenotype is unequal to the sum of their independent contributions [56]. More broadly, it has been treated as the joint effect of multiple genes or SNPs [57]. Therefore, the detection of epistasis can be easily implemented with multi-SNP test [57]. However, a systematic identification of epistasis would theoretically need ∼500 000 individuals, which exceeds even the sample sizes of the majority of meta-GWAS [58, 59]. Previous methods thus *mainly* focus on *pairwise interactions* and ignore important high orders of interactions [60, 61]. Other methods can include three-way interactions by pre- selecting a few SNPs based on the single-SNP tests to reduce the computational burdens [62, 63]. However, these methods *pre-exclude* SNPs with *small marginal effects* but high interactions. Alternatively, *biological information* can be used to reduce the analysis burden, such as *grouping SNPs* into genes or functional modules [34]. Recently, Fang et al. [59] developed a method that identifies high orders of interactions between SNPs based on biological pathways and gene modules (Table 1). Many novel epistases underlying human diseases are discovered with this method [59]. We expect that further improvements in computational methods will allow a systematic analysis of epistasis and shed light on the genetic architecture of complex phenotypes and gene regulation [71].
![[Pasted image 20230412204703.png|1000]]

### Fine-mapping and prioritizing SNPs
Results from GWAS often identify many significant SNPs. A large fraction of them are unlikely to have biological functions themselves but to be in LD with causal SNP or SNPs. Fine-mapping the significant SNPs, therefore, is necessary to prioritize the variants and to convert statistical associations to functional genes [72]. *Lead SNP*, i.e. the SNPs with the *smallest P-values* in the genomic region, may be directly used to indicate causal genes. However, the strongest associations are probably not causal. By simulating 1000 cases and 1000 controls from the 1000 Genomes Project, van de Bunt et al. [73] found that for rare risk allele with 5% frequency and the odds ratio being 1.1, the probability of the lead SNP causing the phenotype is just 2.4%. Thus, relying on solely the lead SNP can be misleading. Alternatively, many studies assess the LD of SNPs with the lead SNP and retain SNPs above a certain *LD threshold* as potentially causal. However, the thresholds chosen are arbitrary and subjective.

Multi-SNP analyses are more frequently used in fine- mapping [53]. The *penalized regression and Bayesian* methods can screen the causal variants by *jointly analysing all significant SNPs*. These methods eliminate coupling SNPs that are merely associated with the phenotype due to their LD with causal SNPs [74–76]. As mentioned above, the penalized regression is a more general *machine learning approach* relying on *prediction accuracy* rather than P-values to select causal SNPs [74]. It overcomes the problems brought by the presence of many correlated SNPs, which leads to traditional unstable regression models [74]. However, the *penalized regression* selects *only one final model* without probabilistic assessment for the final set of casual SNPs [65]. In contrast, *Bayesian* methods offer a few advantages, such as providing comparative *posterior probabilities* for each SNP and improving the power to identify causal SNPs with small effects (Table 1) [65, 72, 77]. Additionally, *functional annotation* data can also be integrated into regression or Bayesian models to aid fine-mapping. The results from real applications have shown that incorporation of annotations can increase the accuracy in fine-mapping the causal variants [75, 76, 78, 79]. However, our current understanding of the genomic functions is still limited. For example, Maller et al. [80] fine- mapped causal SNPs for type 2 diabetes, Graves’ disease and coronary artery disease in the Wellcome Trust Case Control Consortium with a Bayesian method. They found that very few SNPs in the credible sets have been functionally annotated [80]. Thus, integration of annotation data may introduce a bias against unknown gene functions and pathways.
![[Pasted image 20230413102825.png|600]]
## Machine learning
Machine learning is the development of *algorithmic models* that can learn with experience to *identify associations hidden in data* [81]. It has been recognized as the most useful method in genetics and genomics and has been widely used to *interpret large genomic data* and to *annotate* all sorts of genomic sequence elements [82]. In GWAS, machine learning algorithms can identify and prioritize SNPs with small effects [67] (Table 1), provide the mechanistic insights to the genotype–phenotype associations [41] and be robust to extreme outliers of genetic markers.

### Supervised versus unsupervised machine learning
Machine learning algorithms are generally dichotomously grouped into supervised and unsupervised machine learning. *Supervised* machine learning uses *labelled data* and makes predictions about unlabelled examples. *Unsupervised* machine learning, in contrast, can find patterns in the data *without* referring to *labels*. GWAS data are characterized with ‘control versus case’ or ‘healthy versus disease’ phenotype labels. Therefore, the supervised machine learning naturally fits GWAS data. However, *supervised* learning implicitly *assumes* that the *same distribution* is responsible for generating the data that train the model and the new unseen data that the model is adapted to [82]. Thus, a supervised model that is created with, for example, a set of human genes may not be suitable to predicting or identifying similar genes in the mouse genome [82]. Although not widely applied, unsupervised learning is a powerful tool in identifying epistasis [33] and fine-mapping [66]. For example, Lu et al. [66] built an unsupervised learning tool that can provide tissue-specific functional annotations to prioritize significant SNPs (Table 1). Moreover, identifying and separating relevant SNPs that are causal SNPs or show strong LD with causal SNPs from the vast noisy SNPs are similar to detecting outliers that behave abnormally compared with the rest of the data according to some criteria. Unsupervised learning or semi-supervised learning may thus achieve better performances to identifying genotype–phenotype associations [37].

### The basics of machine learning: data, algorithms and model evaluation
Data in machine learning are generally split into three subsets: training dataset, validation dataset and test dataset (Figure 1). Training dataset is the actual data, based on which the model is trained and learns. Validation dataset is used to tune model hyperparameters. In other words, the optimal *parameters* among others are chosen *based* on model *performances* evaluated using the *validation dataset*. A distinctive characteristic of the validation dataset is that the model only sees these data but does not learn from them. The test dataset is used to provide the gold standard assessment of the optimal model performance. When the whole data size is small, cross-validation can be used to train and tune model parameters. Instead of splitting data into three partitions, *cross-validation* divides data into *training and test datasets*. The *training* dataset is *then partitioned into two* complementary subsets: one for training the model and the other for tuning model parameters. The partition of the training dataset is usually performed multiple times to minimize variability. In GWAS, the partition of data may be complicated by the existence of SNP–SNP interactions [83]. Piette and Moore [83] designed the *proportional instance cross-validation* method, which can retain the original structure of the data. This method shows better performance than the traditional cross-validation method [83].

Commonly used machine learning algorithms are random forest, support vector machine (SVM), Bayesian network and penalized regressions (see above). These algorithms overall have low computational burden. **Random forest** is an ensemble learning method that makes predictions based on a number of decision trees (Figure 1). This method is thought to be robust to high- dimensional data and to have a higher power to identify the epistasis [84]. However, this power may decrease as the number of SNPs increases because with increasing data dimensionality random forest tends to capture *marginal effects rather than the effects of epistasis* [85]. **SVM** aims to find a *hyperplane* in the SNP space that *separates control and case* classes (Figure 1). It can implicitly integrate high orders of interactions without predefining them by using *non-linear kernels* [86]. However, *when the number of SNPs exceeds the number of samples*, SVM will *perform worse*. Therefore, *pre-screening SNPs are suggested for SVM*. **Bayesian network** is a probabilistic graphical method to model the conditional dependency, and thus causation, between SNPs and the phenotype of interest using a *directed acyclic graph* (Figure 1) [87]. It overall shows better performances than other methods, such as random forest and penalized regressions, in detecting interactions [88].

*Model evaluation* is another key element in machine learning. *Accuracy* provides the most straightforward assessment of model performance, i.e. the ratio of the number of correctly classified samples relative to all samples. However, when working with *unbalanced* datasets, this measure may be *biased*. For example, for a dataset composed of 100 controls and 10 cases, training and tuning models based on accuracy might falsely select SNPs that classify all samples to controls as causal SNPs with a high accuracy of 0.9. Other metrics are preferred instead of or in addition to accuracy for the unbalanced data. For example, *F1-score* and the area under the receiver operating characteristic curve (*AUC-ROC*) balance precision (i.e. the proportion of correctly identified true positives to all identified true positives) and recall (i.e. the proportion of correctly identified true positives to all true positives) and thus are robust to unbalanced datasets.

### Causal SNP and epistasis identification with the feature selection
Machine learning is the most effective for analysing large, high dimensionality and complex datasets, such as in GWAS. The ‘large p, small n’ problem faced with statistical modelling can be easily handled using machine learning. All SNPs and their interactions (pairwise and high orders) can be integrated into one machine learning model. Relevant SNPs and epistases are identified and prioritized mostly based on a feature selection procedure. *Feature selection* usually is implemented using the supervised machine learning, which selects a subset of features that contribute most to the predicted variable (Figure 1). When carrying out feature selection to identify causal variants, three scenarios need to be distinguished. First, we select the smallest set of SNPs and interactions that build up the *best possible model*. This will directly identify the *strong causal SNPs* if genotyped or sequenced, as in whole-genome sequencing studies. These variants should have high priorities in the follow- up validation studies. Second, we select a subset of SNPs and interactions that build up the *most accurate model*. Such a subset *will include* variants with *small effects* and thus increase the explained genetic variation in complex phenotypes. Third, we select SNPs to understand the underlying *biological mechanisms*. In this case, functional annotations and biological pathways will be integrated into the feature selection procedure, which may offer insightful information about the etiology of disorders.

Feature selection methods can be categorized into *filtering methods and wrapper methods*. Filtering methods rely on the intrinsic characteristics of features. Commonly used filtering methods are chi-squared score, ANOVA, mutual information [89, 90] and AUC-ROC method [33]. The former two belong to statistical modelling (see above). Mutual information assesses the amount of information obtained about the phenotype of interest by the presence of a given SNP. Supposing that X is the genotype value and Y is the phenotype value, the **mutual information** I(Y;X) is defined as: ![[Pasted image 20230413113149.png|200]] where p(x) and p(y) are the marginal probability density function of the genotype and the phenotype, respectively, and p(x, y) is their joint probability density function. *Higher I(Y;X)* values *suggest* potential *causal* variants. Overall, mutual information shows consistent results with chi-square score but *can handle low-frequency alleles* and high orders of *interactions* [33]. Unlike other methods, AUC-ROC method is implemented with the machine learning algorithm. Usually, each SNP is separately used to build the prediction model. SNPs are ranked based on the corresponding model’s AUC-ROC. SNPs with higher scores are selected as relevant SNPs. 

*Wrapper methods* implement a search strategy to get possible SNP subsets. Then, they assess the performances of these subsets for predicting the phenotype of interest. The best subset that maximizes model performance is selected as relevant. Compared with filtering methods, wrapper methods consider the joint effects of multiple SNPs and their interactions and can offer the set of SNPs with the best performance [91]. However, they are very *computationally expensive* and have an increased risk of including irrelevant SNPs (i.e. *overfitting*). Commonly used wrapper methods are **genetic algorithms** [92] and **recursive feature selection** [93].

**Genetic algorithms** were first invented to study the natural adaptation and to translate its mechanism to computer systems [94]. They are composed of three types of operators: selection, crossover and mutation [95]. An initial population composed with n individuals is randomly generated. For *GWAS*, an *individual is a SNP* that is encoded as binary; that is the SNP is either included or not. *Each individual is trained* and its fitness (i.e. model performances) is *assessed*. Individuals are then s*elected with replacement* to *produce offspring* together with *crossover* and random *mutation*. The selection probability is in proportion to the individuals’ fitness, while the crossover probability and the mutation probability are preselected. The *offspring* are used to *form* a new population of size n, which is called a *generation*. With *more generations* produced, the *model* performance is *improved*. After a certain number of runs, the set of individuals with the best fitness can be selected as the relevant SNPs responsible for the phenotype. Genetic algorithms can also be utilized for prioritizing the SNPs [96].

**Recursive feature selection** methods have been shown to outperform other feature selection methods [97]. This approach starts to *train all SNPs individually and ranks* the SNPs in a descending order according to their performances. The model is *retrained recursively by adding one SNP at a time*, in each iteration, based on its rank until some pre-set criteria are met, such as decrease in AUC-ROC [98]. Researchers can also retrain the model backwards, i.e. beginning with all SNPs and removing SNPs recursively one at a time until a reduction in model performance occurs [99]. Another method is to exhaustively search all possible SNP combinations and to find the subset of SNPs with the best performance [100]. However, the latter two methods only work for a small set of SNPs and may need to pre-screen SNPs if the size is large.

Additionally, some machine learning algorithms provide importance measures and can be directly used to identify and prioritize relevant SNPs, such as decision trees [101] and random forest [102]. However, the selection of top SNPs is often arbitrary and subjective. Further, the *importance values* from decision trees and *random forest* are affected by the model parameters and thus are *unstable* [64]. Many remedies use *permutation-based methods* to provide *more* *reliable* estimates, i.e. calculating the difference of model performance before and after permuting the values of a specific variable as the corresponding variable importance value [37, 64].

### Combining machine learning and statistical modelling
Instead of using machine learning alone, combining it with statistical modelling into a two-step model can integrate the strength of the separate methods. One option is to use the *machine learning* in the *first* step to select relevant SNPs with high individual effects and/or high joint effects and then to use multiple statistical hypotheses testing to identify causal associations [29]. Alternatively, statistical tests can be performed preceding machine learning [103]. Both strategies have been shown to be efficient for detecting low-signal linear SNP inter- actions and non-linear interactions [86]. Therefore, the order of machine learning and statistical modelling seems to have few influences to the detecting power [86].

## Perspective
The development of GWAS over the last decade has boosted our understanding of the genetic basis of complex traits. Still GWAS suffer some suspicions and their potential has not been fully exploited. Many believe that current limitations of GWAS will be overcome with larger sample sizes and the replacement of SNP arrays with whole genome sequencing. These necessitate the advancement of methodology and computing in GWAS and post-GWAS analyses. Bayesian methods and machine learning are showing increasing performance and popularity for detecting missed signals, ultra-rare mutations and gene–gene inter- actions and for prioritizing SNPs. Further studies that present a direct, greater comparison between different methods about their performance and reproducibility can aid to understand the role of statistical modelling and machine learning in GWAS analysis. Additional biological insights, such as functional annotations, gene expression and regulatory networks, are also key information to pinpoint causal variants and to understand biological mechanisms that underlie complex traits. However, no single method fits all situations. Researchers may need to adopt different methods according to their investigation questions.

# Machine Learning Approaches and Applications in Genome Wide Association Study for Alzheimer’s Disease: A Systematic Review  (2022)
## Intro
Machine learning algorithms have been used for detection (and possibly) prediction of Alzheimer’s disease using genotype information, with the potential to enhance the outcome prediction. However, detailed research about the analysis and the detection of Alzheimer’s disease using genetic data is still in its primitive stage. The aim of this paper was to evaluate the scientific literature on the use of various machine learning approaches for the *prediction of Alzheimer’s disease* based solely on *genetic data*. To identify gaps in the literature, critically appraise the reporting and methods of the algorithms, and provide the foundation for a wider research programme focused on developing novel machine learning based predictive algorithms in Alzheimer’s disease. A systematic review of quantitative studies was conducted using three search engines (PubMed, Web of Science and Scopus), and included studies between 1st of January 2010 and 31st December 2021. Keywords used were ‘Alzheimer’s disease(s)’, ‘GWAS, ‘Artificial intelligence’ and their synonyms. After applying the inclusion/exclusion criteria, 24 studies were included. Machine learning methods in the reviewed papers performed in a wide range of ways (0.59 to 0.98 AUC). The main findings showed that high risk of bias in the analysis can be linked to feature selection, hyperparameter search and validation methods.

One of the most significant scientific issues in the human genome is the study of genetic variants connected to com- plex illnesses. The bulk of genome-wide association studies (GWAS) [1] attempt to identify genetic variations that may be connected to complicated illnesses. Single nucleotide polymorphisms (*SNP*) are known to be the most prevalent genetic variations, with around 10 million SNPs in the human genome [2]. A single nucleotide site is one in which a significant fraction of the population has exactly two (of four) unique nucleotides. There are two known ways in which SNPs play a significant role in the disorders’ complications. First, by changing the *protein structure*. Second, via altering the *protein quantity*. This process is referred to as SNP functionality. Genetic association research attempted to explore genetic risk factors by identifying statistical connections between genotypes and phenotypes (disease of interest). The most popular method for determining the genetic connections of complicated disorders is to conduct *case-control studies* in unrelated individuals.

Machine learning (ML) has emerged since a decade an alternative for genetic predictions and has shown prominence especially after the developments in deep learning [3]. This emerged in line with scaling-up of datasets and computa- tional capacity. In statistical genetics, where the effects of a large number of factors on an outcome were difficult to anticipate, *ML* techniques have been intriguing because of their capability to operate in *high dimensions* and identify *relations across genes* [4]. There have also been more requests to employ ML to handle the complexity of diseases such as Alzheimer’s disease [5]. However, the *accuracy of* machine learning approaches in *predicting* Alzheimer’s disease using genetics is still vague, and a new review of prediction models across a variety of outcomes and predictors discovered that *logistic regression (LR) provided high accuracy*, and hence the use of machine learning in this research field is questionable [6].

Various reviews have examined genome-wide association research and genetic prediction in relation to ML. The first conducted by Bracher-Smith et al [7] that examined machine learning algorithms for *identifying mental health diseases based only on genetic information*. Second, Madhukar et al. [8] discuss bioinformatics ideas for leveraging sequencing data to predict sample-specific *medication susceptibility*. Third, Upstill-Goddard et al. [9] provided a review of machine learning methods in genetic epidemiology for detecting *gene-gene interactions*. The most essential machine learning approaches and the circumstances that must be addressed when applying these algorithms to genomic challenges were discussed in [10]. The goal is to find and analyze GWAS concerns that require computational approaches instead of or in addition to biostatistical methods [11]. Data mining and machine learning computational methodologies, as well as bioinformatics methods for embedding pre-existing biological knowledge into data analysis algorithms, were the focus of other research work carried out by Wu and Zhao [10]. A review of illness prediction based on single-nucleotide polymorphisms has been undertaken by Ho et al. [12]. A recent systematic review of ML algorithms in SNP data of Alzheimer’s disease is shown by Rowe et al. [13]. However, the main limitation of the research paper provided by Rowe et al. [13] is the fact that they have utilized machine learning as a keyword for their search and presentation instead of investigating specific ML techniques. Hence, their review paper does not provide sufficient details on the contribution of various research in relation to the use of ML for the analysis of SNP data of AD. Their inclusion criteria involved studies which combined SNP data with other forms of data. As far as we are aware, there have been no reviews of studies which have **developed ML models to predict AD outcomes from SNP data** specifically.

As a result, in our review study, we have looked at extensive literature review for the ability of machine learning (ML) techniques to predict Alzheimer’s disease risk using genetic based on the Genome Wide Associations study. The goal of the review is to identify gaps in the literature, critically appraised the reporting and methods of the algorithms and provide the foundation for a wider research program focused on developing novel machine learning based predictive algo- rithms in AD. It should be noted that studies in which models were also tested on simulated datasets or other chronical diseases alongside Alzheimer’s disease are also considered in this comprehensive review paper. Preferred Reporting Items for Systematic Reviews and Meta-analyses (PRISMA) crite- ria were followed for writing this review.

## Theoretial Background
Big data is a collection of big, structured or unstructured data sets that a typical database system struggle to manage. ‘‘Big data’’ refers to the tools and procedures that enable an organ- isation to produce, utilise, and store huge volumes of data with storage facilities [14]. Big data is usually defined by five characteristics that, within the context of genetics, include: volume, variety, velocity, veracity and variability. In terms of volume, GWAS requires the genotyping of thousands or millions of genotypes for each participant which in total for a complete GWAS produce a massive amount of data. For variety, a mixture of data types needs to be stored and handled that is made across several files for genotype data and individuals’ information. For velocity, the fast advancement of GWAS has been aided by the availability of genotyping technologies. These genotyping technologies were created expressly for assaying more than one million SNPs, such as sequencing the whole human genome in one day [15]. For veracity, errors in the genotyping process can result in data quality concerns that are difficult to spot, which can have a significant impact on a study’s biological results [16]. For variability: GWAS dataset can be stored in different formats. However, it is preferable to save the data in a binary formatted file, which results in a large decrease in file size and a significant increase in computing performance. Figure 1 shows a graphical representation of the big data in GWAS. 大数据是大型的结构化或非结构化数据集的集合，典型的数据库系统很难管理这些数据集。“大数据”指的是一种工具和程序，使一个组织能够通过存储设施产生、利用和存储大量数据。大数据通常由5个特征定义，在遗传学的背景下，包括:体积、多样性、速度、准确性和可变性。在数量上，GWAS需要对每个参与者进行成千上万种或数百万种基因型的分型，一个完整的GWAS需要产生大量的数据。对于多样性，需要跨多个文件存储和处理基因型数据和个人信息的混合数据类型。在速度方面，gwas的快速发展得益于基因分型技术的可用性。这些基因分型技术是专门为分析100多万个SNPs而发明的，比如在一天内对整个人类基因组进行测序。为了准确性，基因分型过程中的错误可能会导致难以发现的数据质量问题，这可能会对研究的生物学结果[16]产生重大影响。对于可变性:GWAS数据集可以以不同的格式存储。但是，最好将数据保存在二进制格式的文件中，这样可以大大减少文件大小，并显著提高计算性能。图1显示了GWAS中的大数据的图形表示。
![[Pasted image 20230413130253.png|500]] ![[Pasted image 20230413135055.png|250]] ![[Pasted image 20230413135125.png|250]] 

Machine Learning (ML) simulates human learning by allowing computers to recognise and gain knowledge from the actual world, as well as enhance performance on particular tasks depending on this new information. ML was explored as a separate discipline in the 1990s [17], despite the fact that the earliest notions of ML (with different terminologies) were developed in the 1950s. Apart from computer science, ML algorithms have being applied in a variety of fields, including business [18], advertising [19], and medicine [20].

Learning is the process of gaining information, because of their ability to reason, humans naturally learn from their experiences. Conventional computers, on the other hand, do not learn by thinking rather by following algorithms. There are several machine learning algorithms presented in the literature nowadays. They may be divided into groups based on how they approach the learning process, *supervised, unsupervised, semi supervised*, and *reinforcement learning* are the four primary classes [21]. Figure 2 shows ML types: a) Supervised learning works with data that has been labelled; in the instance of GWAS, the SNPs data is entered as inputs with corresponding labels, the ML model will automatically generate patterns and produce predictions for new unseen inputs; b) Unsupervised learning learns pattern from unlabeled data inputs. in the area of genetics, unsupervised learning can be used to cluster genes that have a common characteristic; c) Semi-supervised learning, the model accepts labelled and unlabeled datapoints; d) reinforcement learning is to feed the model with unlabeled data, then the model generates predictions, which can be approved by providing feedback to the model on whether that prediction was correct or not.

With the growth in processor speed and memory size, machine learning has become increasingly popular. As a result, the discipline currently contains a wide variety of algorithms that learn, draw conclusions, or infer facts through mathematical or statistical analysis [22]. The number of scholarly articles proposing modifications or combinations of machine learning algorithms continues to rise [23], [24]. As a result, machine learning algorithms have been classified according to their intended use.

### 1) Artifical Neural Network
Artificial neural network (ANN) is a densely connected network of hundreds or even millions of fundamental processing nodes loosely modelled after the human brain. The vast majority of today’s artificial neural networks are ‘‘feed- forward,’’ meaning that information only goes one way through them and they are organized into layers of nodes. However, there exist other types of ANN that accept feedback connections. These are mainly known as recurrent neural networks. They are characterized by their ‘‘memory,’’ which allows them to impact current input and output by using knowledge from previous inputs. While typical deep neural networks presume that inputs and outputs are independent of one another, recurrent neural networks’ output is reliant on the sequence’s prior components. While future occurrences may be useful in establishing the outcome of a series.

Nodes in a layer can be fully or partially connected to the nodes of a previous layer from which it obtains the data. Simi- larly, the nodes are connected and send data to the nodes of the succeeding layer. Figure 3 illustrates an ANN representation.

The process of training an ANN starts by randomly set- ting the values of weights and thresholds. The input layer receives the training data, which is subsequently multiplied and combined in different complex ways until it reaches the output layer. The values of weights are continually adjusted throughout the training process.

Initially, the perceptron of a very basic artificial neural network consisted of only two inputs and one output [25]. This setup enables the creation of a basic classifier that can discriminate between two groups. ANN then evolved into a Multilayer Perceptron, which consists of three layers: input, hidden and output. This development has allowed us to solve more complex non-linear problems [26].

Due to the increase in the volume of data and the com- plexity of the problems associated therewith, a new subset of machine learning algorithms was established known as deep learning. Deep learning (DL) excelled with its ability to auto- matically learn characteristics from data and the relationships between data points [27].

An ANN architecture with numerous hidden layers and neurons is the basic architecture in deep learning. Various designs have been suggested, and many of them have found success in various applications including the analysis of genetic data. Convolutional neural networks are deep learn- ing structures inspired by human visual cortex models that have been widely used in image recognition. Recurrent arti- ficial neural networks, which imbue neurons with dynamic behavior, have emerged as the most popular approach for dealing with time series data and natural language processing [28].

Deep learning is a powerful tool for GWAS data analysis, mainly because the amount of data is enormous, far beyond our limited reasoning abilities. In genetic applications, a deep ANN can be built with nodes representing genetic elements (SNPs) and arcs indicating connections (interac- tions) between the elements.
