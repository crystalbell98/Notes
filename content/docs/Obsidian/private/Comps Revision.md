1. First, the key theoretical concepts, mechanisms, and predictions need much more elaboration, especially in the **introduction**
	- [x] more elaboration regarding theoretical accounts for *why/how educational attainment* could mitigate the impact of neuropathological burden. 
		- Cognitive reserve (maybe in discussion: peak cognition theory)
	- [x] more development of the key ideas, with a clear explication for why and how education might mitigate neuropathology, and *what the alternatives would like* (e.g., education as simply a positive main effect).
		- [x] Need collect main effect of education?
1. Second, Results & **Discussion**
	- [x] key information needed to assess the *strength* and potential *contribution* of this meta-analysis is missing from the methods and results (including the tables).
	- [x] I was thrown by the “*As expected*...” opening for the sentence about weak support for the hypothesis. I didn’t get the sense that weak support was expected. I think a more expansive discussion is warranted overall, and is needed specifically to address this point of confusion.
		- This is cursory. Says results are “as expected” but why? Where was this prediction laid out and explained? Discussion doesn’t mention that the CI for the .12 SD decrease includes zero (as per the abstract). Etc
		- I originally want to say the direction is as expected protective way.......
	- [x] I wasn’t sure that the description of the *subgroup analyses* on page 5 corresponded to what was reported in *Table 2*. Why the *focus on non-significant effects* in the Discussion? More to the point, I didn’t think that these values were statistically *compared to one another*, which is what would be needed to talk about effects being stronger or weaker in some domains than others.
	- [x] The description of the methods used, the results found, etc. seems limited to me. The end result of the paper and its conclusions seem limited, too, because of the limited results section
2. Third, **Methods** Part
	- [x] there was concern about ==combining different outcomes and measures== of pathology into a single effect size estimate.
		- [x] Interpreting the results of the big model is challenging since the effect sizes cannot be compared across different outcomes. It might be more suitable to perform the primary analysis by *stratifying it either by outcome* or *by both outcome and pathology measure*
		- [ ] It might not be appropriate to combine the effect sizes from *models with different covariate adjustments*, particularly the models involving extra edu interaction or pathology adjustment. The effect  sizes and standard errors may not be comparable across studies.
		- [x] There is no description of the variability or systematicity of results. The figure has memory, executive function, etc. for domains of functioning and also has a bunch of measures of pathology but then the results are discussed as though there is only one result. It's *simplistic*.
		- [x] multiple outcomes or multiple pathologies” I assume this is how we get from 21 studies to 90 odd regression coefficients—again would like to see more detail on this. *Can you really do* a meta-analysis that combines *across different “outcomes”*?
	- [x] more elaboration around the search and screening process under “Search Strategy” as to determining whether papers were *eligible for inclusion* (e.g., identification of duplicates, review of abstract, review of full text, etc.) and the number of papers deemed ineligible at each stage. Fig. 1 seems to suggest that there was additional review *undertaken from the reference* sections of eligible papers, but this is not described in search strategy.
	- [x] Data Coding & Extraction: Some commentary as to why *race* and ethnicity were *not coded* demographic variables seems warranted. Better add a column for race in Table 1
	- [x] Need to *clarify the differences* among models 4, 5, 6, 7, 8, and 9 in study 16. The outcomes and pathology measures seem to be the same
	- [x] *21 papers* does *not* seem like very *many*—this is worthy of some discussion. Why is it or is it not a *problem?*
	- [x] *Some studies* appear *under powered*—did not see discussion of power. Sometimes it is recommended to *leave low power studies out* of a meta analysis—would this change results? I’m guessing not, given the lack of evidence for publication bias (love that figure, btw) but again, more discussion needed.
		- I excluded 2 studies with fair quality in sensitivity analysis.
	- [x] *Inclusion/exclusion criteria*—these are clear enough but some *justification* would be good (e.g., why exclude medication therapy studies? Were non-medication intervention studies included?
	- [x] More info needed on the analyses. Were these *all linear regressions* in these *studies*? A combination of different ones? If linear, why not use *R2* for the interaction term as *effect size*, which seems more straightforward?
3. Writing
	- [x] switch between terms like “education* neuropathology” and “education* brain status.” Suggest adopting consistent language throughout
	- [x] I wasn’t clear on the meaning of the terms “exposed” and “unexposed” in the Quality of Studies section. Exposed/unexposed to education? To pathology?
		- to both of them
	- [x] I also think the *writing* in general could be improved -- certainly it could be better organized

![[Pasted image 20230821103626.png|600]]



when interpret the individual main effect of variable A  with the interaction A* B in the model at the same time, it is important to know whether A and B is centered 