# Linear Mixed Model
- Before using hierarchical models, explore the data with a plot and linear model. *Plotting data* gives you visual intuition and allows you to see potential trends or problems. Building a simple model provides a comparison to a hierarchical model. Building a simple linear model provides a starting place for hierarchical models and troubleshooting the linear model is quicker and simpler than a hierarchical model.
	- ` ggplot(data = student_data, aes(x = mathknow, y = mathgain)) +geom_point() +geom_smooth(method = geom_smooth)`
		- ![[Pasted image 20231106135407.png|300]] 
	- `summary(lm(mathgain ~ mathknow , data = student_data))`
		- ![[Pasted image 20231106135529.png|300]]
- In the last exercise, the simple linear model you used did not account for the structure of the data. Students learn within classrooms and classrooms exist within schools, which means students within the same classroom are not independent. One solution is to collapse the data by taking a mean for each level. However, the method used to collapse the data can be important, especially for small or unequal-sized groups. In this exercise, you will *aggregate the gains in math scores* (`mathgain`) three different ways. After summarizing the data, you will examine a linear model of the data at each level. 
	- ![[Pasted image 20231106142023.png|400]]  ![[Pasted image 20231106141332.png|300]]
	- ![[Pasted image 20231106141528.png|400]] ![[Pasted image 20231106141607.png|400]] 
	- ![[Pasted image 20231106141730.png|400]] ![[Pasted image 20231106141800.png|400]] 
- Regression
	- ![[Pasted image 20231106143031.png|300]] 
	- **Intercepts** are an important part of regression models, including hierarchical models, and allow the modeling of discrete groups. Without other coefficients, a single intercept is the global *mean* of the data. This model is also called a _null model_ by some. Similarly, multiple intercepts allow you to estimate the mean for each group as long as other coefficients are not estimated.
		- During this exercise, you will learn about *intercepts and* see their *relationship to means*. You will look at a subset of the school data that only includes student data from the school with the id code of `3`. This data has been loaded for you as `school_3_data`.
			- ![[Pasted image 20231109091633.png|300]] ![[Pasted image 20231109092432.png|300]] ![[Pasted image 20231109092547.png|300]] 
	- Previously, you used multiple **intercepts** to model the expected values for discrete groups. Now, you will model continuous predictor variables with **slopes**.
		- In particular, you will model gains in math test scores by building three different models. The data, `school_3_data`, has been loaded for you.- With the data `school_3_data`, model a student's math gain (`mathgain`) being predicted by class (`classid`) and score (`mathkind`). Estimate a coefficient for each classroom using a `- 1` at the end of your formula.
		- ![[Pasted image 20231109093010.png|300]]
- random effect
	- Linear models in R estimate parameters that are considered _fixed_ or non-random and are called _fixed-effects_. In contrast, _random-effect_ parameters assume data share a common error distribution, and can produce different estimates when there are small amounts of data or outliers. Models with both fixed and random-effects are _mixed-effect_ models or _linear mixed-effect regression_.
	- ![[Pasted image 20231004133918.png|300]]
		- This equation depicts a simple random effect. The equation on top is the relationship to the data given the i-th beta. The random effect assumes that beta is drawn from a normal distribution with the mean, mu, and the standard deviation, sigma. This is the algebraic representation of the multi-level model.
	- ![[Pasted image 20231004134107.png|300]] 
		- To specify a random slope, we use parentheses slope - pipe - random effect group.
		- The *lme4* package fits mixed-effect models (models with both fixed- and random-effects) with `lmer()`, which uses a formula similar to `lm()`.But, **random-effect intercepts use special syntax**: ```lmer(y ~ x + (1 | random-effect), data = my_data)``` , `lmer()` function _requires_ the model to include a random-effect, otherwise the model gives you an error. **Note:** `broom.mixed` is required because the `broom` package does not support `lme4`.
	- **Exercise**: ![[Pasted image 20231109093616.png|300]]
		- Here, you will fit a `lm()` and a `lmer()`, and then graphically compare the fitted models using a subset of the data. We provide this code because of the advanced data wrangling, which is required because random-effects are usually not plotted (`ggplot2` also does not include nice plot options for mixed-effect models). In this plot, notice how the **dashed** lines from random-effect slopes compare to the **solid** lines from the fixed-effect slopes.
			- ![[Pasted image 20231109094214.png|500]] ![[Pasted image 20231109094253.png|300]] 
			- ![[Pasted image 20231109095003.png|500]] ![[Pasted image 20231109095121.png|300]] 
		- In the previous exercise, you saw how to code random-effect intercepts. You will now see how to code random-effect slopes. With `lme4` syntax, `lmer()` uses `(countinuous_predictor | random_effect_group)` for a random-effect slope. When *lme4* estimates a random-effect slope, it also estimates a *random-effect intercept*. `scale()` rescaled the predictor variable `mathkind` to make the model more numerically stable. Without this change, `lmer()` cannot fit the model. In the *previous* exercise, you estimated a *random-effect intercept* for *each classroom* and *one `slope` for all data*. **Here**, you will estimate a random-effect intercept for each class and a *random-effect slope for each classroom*. Like a random-effect intercept, a random-effect slope comes from a shared distribution of all random-effect slopes.
			- ![[Pasted image 20231109101405.png|500]] ![[Pasted image 20231109101446.png|400]] 
		- You will now built a model to examine what factors predict a student's gain in math knowledge. As described in the video, you will build a model to see:
			1. Does the sex of a student impact their knowledge gain?
			2. Does the teacher's training impact the gain and does the teacher's math knowledge impact the gain?
		- As part of this model, you will also account for other possible predictors including:
			- Does a student's math knowledge in kindergarten impact their gain?
			- Does a school's socio-economic status impact student gains?
			- ![[Pasted image 20231109102142.png]]
			- ![[Pasted image 20231109102252.png|500]] ![[Pasted image 20231109102353.png|400]] ![[Pasted image 20231109102426.png|600]] 
	- **Exercise** ![[Pasted image 20231109104129.png|300]] 
		- In the video, you learned about the county-level birth rate data. Counties exist within states and perhaps states contribute to variability. During these exercises, you'll build a series of mixed-effects models using this data. In this exercise, you'll build a hierarchical model with a global intercept (*fixed-effect*) and *random-effect for state*. You will then look at the `summary()` of the model and the `plot()` of the residuals. Like other types of regression analysis, *examining residuals* can help you see if anything is wrong with the model. With `lmer()`, there are two methods for doing this: `y ~ 1 + (1 | random_effect)` or the shortcut, `y ~ (1 | random_effect)`. Use the shortcut in this exercise so that your answer passes the DataCamp test. When building mixed-effect models, starting with simple models such as the global intercept model can check to see if problems exist with either the data or code. A _global intercept_ assumes a single intercept can describe all of the variability in the data. One way to view a global intercept is that you cannot do any better modeling that data than to only model the mean without including any other predictor variables.
			- ![[Pasted image 20231109105011.png|400]] ![[Pasted image 20231109105032.png|500]] 
			- ![[Pasted image 20231109105451.png|500]] ![[Pasted image 20231109105407.png|400]]
			- ![[Pasted image 20231109110307.png|500]] 
		- In the previous exercise, you estimated random-effect intercepts for each state. This allowed you to account for each state having its own intercept. During this exercise, you will estimate a random-effect slope for each state. For example, perhaps the log10(total population of each county), `LogTotalPop`, changes the birth rate of a county **AND** varies by state. Recall from the video, a random-effect `slope` may be estimated for each `group` using `(slope | group)` syntax with `lmer()`. During this exercise, fit a mixed-effects model estimating the effect of the mother's average age while accounting for state and total population as random-effects. To fit a model with an *uncorrelated random-effect slope*, use `||` rather than `|` with `lmer()` syntax.
			- ![[Pasted image 20231109131327.png|500]] 
			- Fitting `model_c` gave a _singular_ warning message. In this case, the more complex model is required. The results from `model_B` provide insight into why. Specifically, look at the summary of `model_b`. Which statement is true?
			- ![[Pasted image 20231109131614.png|600]] 
		- In the previous exercises, you fit mixed-effect models with different fixed- and random-effects. Sometimes, a model can have the *same predictor as both a fixed and random-effect*. For example, perhaps you are interested in estimating the average effect the age of a mother at birth (`AverageAgeofMother`). Including the predictor as fixed-effect allows you to estimate the effect of a mother's age across all locations. Including the predictor as a random-effect allows you to simultaneously account (or _correct_) for different slope estimates among states.
			- ![[Pasted image 20231109132121.png|500]] 
	- One of the first things to examine after fitting a model using `lmer()` is the *model's output* using either the `print()` or `summary()` functions. Although similar, each produces slightly different outputs. The purpose of this exercise is to have you compare the two outputs and then answer a question about how the two differ. A `lmer()` model has been fit for you and saved as `out`. We often want to know what values a model estimates as coefficients. Although the `summary()` function provides the model outputs, we might also want to directly access model outputs. The fixed-effects estimates can be called directly using the `fixef()` function. The random-effects estimates can be called directly using the `ranef()` function. We can also extract confidence intervals for the fixed-effects using the function `confint()`. The `broom.mixed` package also contains _tidy_ methods for extracting model results from `lmer()` models, namely the `tidy()` function. However, these results are more complex and less _tidy_ than many tidy outputs due to the complexity of mixed-effect models.
		- ![[Pasted image 20231109132846.png|400]] 
	- Data scientists must communicate their work and DataCamp offers [courses on the topic](https://www.datacamp.com/courses/communicating-with-data-in-the-tidyverse). Explaining your work helps your audience understand the results. To do this, match your presentation to your audience's knowledge level and expectations. For non-technical audiences, describe the important findings from your output. For example, you might say, _counties with older mothers tend to have lower birth rates_. For technical audiences, include details such as coefficient estimates, confidence intervals, and test statistics. Books such as _The Chicago Guide to Writing about Multivariate Analysis_ provide suggestions for describing regression outputs. During this exercise, you will **extract and plot fixed-effects**. Besides **plotting the coefficients** (with `geom_point()`) and their 95% confidence intervals (with `geom_linerange()`), you will add a red-line to the plot to help visualize where zero is located (using `geom_hline()`). If the 95% confidence intervals do not include zero, the coefficient's estimate differs from zero. `coord_flip()` is required because `ggplot` does not allow for `xmin` or `xmax`, only `ymin` and `ymax`. And, `theme_minimal()` changes the theme from the default. **Technical note:** Extracting regression coefficients from `lmer` is tricky (see the [discussion](https://github.com/tidyverse/broom/issues/96) between the `lmer` and `broom` authors).
		- ![[Pasted image 20231109135117.png|500]] ![[Pasted image 20231109135137.png|400]] 
 - Applying mixed-effect models requires the use of **statistical inferences**. During this lesson, we will talk about two different methods with mixed effect models: Null-hypothesis testing of covariates and applying analysis of variance or ANOVAs to compare models.
	 - ![[Pasted image 20231109135411.png|300]] 
	 - By default, the lme4 package does not include p-values. There are several reasons for this. First, p-values cannot be estimated for the random-effects because these are latent variables without standard deviations. Second, estimating p-values for fixed-effects within a mixed-effect model is currently an open research question, which includes an on-going debate on the best practices for how to calculate degrees of freedom. However, several ad-hoc packages do exist. One such package is lmerTest. We'll use this package in our exercises. 
	 - Analysis of variance or ANOVA is a powerful statistical tool. Usually, it is used to compare variance within and between groups to see if the groups differ from each other. ANOVA can also be used to compare mixed-effect models. When applying ANOVAs to mixed-effect models, we compare the variability explained by one model to the variability explained by another model. The model that best explains the variability is the one we use. For example, if we wondered whether a specific response variable was important, we could build two models, one with the parameter and one without. The model that the ANOVA said did a better job of explaining the variability would be the model we want to use with our data.
	 - *Visualizing Maryland crime data*. Before fitting a model, plotting the data can be helpful to _see_ if trends or data points jump out, outliers exist, or other attributes of the data require future consideration. Using `ggplot2`, you can plot lines for county and examine how crimes change through time. For this exercise, examine Maryland crime data (`md_crime`). This includes the `Year`, a count of violent `Crime`s in the county, and the `County`'s name. To explore this data, first plot the data points for each county through time. This lets you see how each county changes through time. Rather than using an aesthetic such as `color`, `group` is used here because there are too many counties to easily distinguish colors. After plotting the raw data, add trend lines for each county. Both the connect points (`geom_line`) and trend lines (`geom_smooth`) provide insight into what, if any, kinds of random effects are required. If all of the points appear to have similar ranges and means, a random-effect intercept may not be important. Likewise, if trends look consistent across counties (i.e., the trend lines look similar or parallel across groups), a random-effect slope may not be required.
		 - ![[Pasted image 20231109140114.png|400]] ![[Pasted image 20231109140136.png|400]] 
		 - The last plot showed changes in crime rate varied by county. This shows you that you should include `Year` as both a random- and fixed-effect in your model. Including `Year` this way will estimate a global slope across all counties as well as slope for each county. The fixed-effect slope estimates the change in major crimes across all Maryland counties. The random-effect slope estimates model for that counties have different changes in crime. But, fitting this model produces a warning message! To address this warning, *change `Year` from starting at 2006 to starting at 0*. We provide you with this new variable, `Year2` (e.g., `2006` in `Year` is `0` in `Year2`). Sometimes when fitting regression, you need to scale or center the intercept to start at 0. This improves numerical stability of the model.
			 - ![[Pasted image 20231109140447.png|500]] ![[Pasted image 20231109140505.png|400]] 
	 - Null hypothesis testing. Null hypothesis testing uses [_p_-values](https://en.wikipedia.org/wiki/P-value) to test if a variable differs _significantly_ from zero. Recently, the abuse and overuse of null hypothesis testing and p-values has caused the American Statistical Association to issue a statement about [the use of p-values](https://www.amstat.org/asa/files/pdfs/P-ValueStatement.pdf). Because of criticisms such as these and other numerical challenges, Doug Bates (the creator of the `lme4` package) [does not include p-values as part of his package](https://stat.ethz.ch/pipermail/r-help/2006-May/094765.html). Yet, you may still want or need to estimate p-values. To fill this need, several packages exist, including the `lmerTest` package. `lmerTest` uses the same `lmer()` syntax as the `lme4` package, but includes different outputs. During this exercise, you will fit a `lmer()` model using `lmerTest` and `lme4`.
		 - ![[Pasted image 20231109140839.png|400]] ![[Pasted image 20231109141051.png|800]] 
	 - *Model comparison with ANOVA*. Comparing models can be difficult. Many methods exist although these are beyond the scope of this course such as model selection (e.g., AIC). Analysis of Variance (ANOVA) exists as a basic option to compare `lmer` models. The ANOVA tests to *see if one model explains more variability than a second model*. The ANOVA does this by examining the amount of variability explained by the models. For example, you can see if `Year` predicts `Crime` in Maryland. To do this, build a null model with only `County` as a random-effect and a year model that includes `Year`. You can then compare the two models using the `anova()` function. If `Year` explains a significant amount of variability, then the _P_-value will be less than your pre-specified threshold (usually 0.05).
		 - ![[Pasted image 20231109145629.png|400]] 

# GLM
**Linear mixed models**, like linear models, assume normality. More precisely, the models assume that the *residuals of the model are normal*. However, data often does not meet this assumption. Historically, *one solution was to transform the data*. For example, with proportion data, 10% of respondents might answer yes to a question. Historically this would be transformed using an arcsine transformation. However, advances in modeling now allow us to directly model the raw data. Hence, a recently published ecology article proclaims that the "arcsine is asinine". For example, **R can now readily model non-normal** distributions, such as *counts data, using Poisson distributions* and *proportions using binomial distributions*. The generalized linear model or glm() function uses the same formula notation used by the linear model function. Unlike the lm() function, the glm() function in R allows for different "families" of distributions to be fit. *These families are the error distributions and how the error distributions are linked to the observed data*. The default glm family is the Gaussian or the normal distribution. A glm() with a Gaussian distribution is the same as lm(). All families in base R are listed in their help file. 

When dealing with **count** data, the first distribution I consider is the Poisson distribution. This distribution models data where a certain *number of events occur per unit area or time*. For example, we could use a Poisson error term to model the number of visitors to a website per hour. The example Poisson distribution plotted here has a mean of 3. Notice how the distribution requires discrete values that are positive. The distribution also assumes the mean is equal to the variance. The Poisson distribution *works well for small counts that are less than approximately 30 observations*. If there are more than 30 observations, another distribution, such as the normal, will usually be more appropriate.

Oftentimes, I deal with **binary** data that has either a zero or a one as an output. For example, we might be interested in the probability of an answer yes, indicated by a one, or no, indicated by a zero, to a question. A logistic regression, or more broadly, binomial regression allows these outcomes to be modeled.
	To fit a logistic regression in R, the glm() function is used with a binomial error term. A glm() in R has three methods for inputting binomial data: the data can be in a "binary" format, the data can be in the *"Wilkinson-Rogers" format*, or the data can be in a *weighted format*. All three approaches produce the same coefficient estimates, but differ in the degrees of freedom and resulting deviance values. *The last two methods consider the data as having fewer observations* and therefore, fewer degrees of freedom, because they use each treatment for the number of observations, not the actual observations themselves. You will get to see all three methods in the exercise.
	![[Pasted image 20231109150333.png|500]] 
- Exercise:  **Logistic regression**. In toxicology studies, organisms are often dosed and binary outcomes often occur such as dead/alive or inhibited/mobile. This is called a [dose-response study](https://en.wikipedia.org/wiki/Dose%E2%80%93response_relationship). For example, the response to different doses might be mortality (1) or survival (0) at the end of a study. During this exercise, we will fit a logistic regression using all three methods described in the video. When using the "wide" or "short" data frame, the "success, failure" methods for inputing logistic regression results require success and failure be a matrix. The easiest way to do this is with the `cbind()` function. **Tip:** When working with data _in the wild_, always check to see what `0` and `1` correspond to. Different people use different notation and assumptions can cause problems for you if you assume wrong! You have been given two datasets.
	- `df_long`, in a "long" format with each row corresponding to an observation (i.e., a 0 or 1).
	- `df_short`, in an aggregated format with each row corresponding to a treatment (e.g., 6 successes, 4 failures, number of replicates = 10, proportion = 0.6).
	- ![[Pasted image 20231109151735.png|300]] ![[Pasted image 20231109152322.png|400]] 
	- ![[Pasted image 20231109151229.png|400]] ![[Pasted image 20231109151654.png|400]] ![[Pasted image 20231109152005.png|400]] 
- **Poisson Regression**. A Poisson regression is another type of GLM. This requires integers or count data (i.e., 0, 1, 2, 3, …). For some situations, a Poisson regression can be more powerful (e.g., detecting statistically significantly trends) than a linear model or "Gaussian" regression. During this exercise, we're going to build a linear regression using the `lm()` function and a Poisson regression using `glm()`.
	- ![[Pasted image 20231109153324.png|400]] ![[Pasted image 20231109153351.png|400]] 
- **Plotting GLMs**. Often, we want to "look" at our data and trends in our data. `ggplot2` allows us to add trend lines to our plots. The default lines are created using a technique called [local regression](https://en.wikipedia.org/wiki/Local_regression). However, we can specify that different models are used to create the lines, including GLMs.
	- ![[Pasted image 20231109153535.png|500]]  ![[Pasted image 20231109153603.png|400]] 
	- ![[Pasted image 20231109153729.png|400]]  ![[Pasted image 20231109153752.png|400]] 
- **Binomial data**. Some data only has two outcomes; this data can be called binomial, like binary zeros and ones. Traditionally, one method to analyze this data was to calculate the proportion of "successes" or other similar variables. However, with a generalized linear model, we can directly model the zero or one outcome. These models are known as logistic regressions or probit analysis. **Binomial data with glmer**. The syntax for fitting a generalized linear mixed effects model or generalized linear mixed effects regression (glmer) model is a combination of the lmer and a glm functions. We need to specify both a random effect and an error term. Note that unlike the glm() function, the glmer() function requires a non-Gaussian error term, otherwise we will get an error.
	- ![[Pasted image 20231109154121.png|300]] 
	- *Toxicology data.* A toxicologist wonders if exposure to a chemical increases mortality as its dose increases. She has exposed test organisms to different doses of a chemical and recorded the number that died in each test tank. Each dose was repeated on three different days. First, build a GLM. Building a simple model makes debugging easier. Also, you will later compare the results to GLMER. This model includes `dose` and `replicate` as a fixed-effects. Second, build a GLMER. This time, `dose` is a fixed-effect and `replicate` is a random-effects intercept. Last, examine the coefficient estimates with `coef()` from each model. Notice how the intercept estimates are displayed differently from each model.
		- ![[Pasted image 20231109155604.png|400]] 
	- *Marketing example*. As described in the video, our client is interested in knowing if a friend's recommendation increases the number of people who buy, rather than pass, on his online product. He has given us a summary of his data as a `data.frame` called `all_data`. This data includes the number of `Purchases` and `Pass`es for 4 test cities (`city`) as well as the customer `ranking`. This data structure lends itself to using `cbind()` on the two columns of interest to create a matrix (You could use other methods of making a matrix in R, but this is one of the easiest methods). You are interested to see if the recommendation from a `friend` increases people buying the product. To answer this question, you will build a `glmer()` model and then examine the model's output. If the parameter estimate for `friend` is significantly greater than zero, then a friend's recommendation increases the chance somebody makes a purchase. If the parameter estimate for `friend` is significantly less than zero, then a friend's recommendation decreases the chance somebody makes a purchase. If the parameter estimate for `friend` is not significantly different than zero, then a friend's recommendation has no effect on somebody making a purchase.
		- Fit a `glmer()` with `all_data` `data.frame`. Use `cbind(Purchases, Pass)` being predicted by `friend` and `ranking` (`friend` goes first). Use `city` as your your random-effect and `family = "binomial"`.
		- `cbind()` is required because `glmer()` requires a matrix input.
		- ![[Pasted image 20231109160146.png|300]] ![[Pasted image 20231109160303.png|400]] 
		- ![[Pasted image 20231109160113.png|500]] 
		- *Calculating odds-ratios*. In the previous exercise, we saw how to compare the effects of a friend's recommendation on sales. However, regression outputs can be hard to describe and sometimes odds-ratios can be easier to use. **Note on course code:** Since this course launched, the `broom` package has dropped support for `lme4::lmer()` models. If you try to repeat this on your own, you will need the `broom.mixed` package, which is on [cran](https://cran.r-project.org/web/packages/broom.mixed/vignettes/broom_mixed_intro.html). Using the outputs from the previous exercise, we're going to calculate odds-ratios. **Refresher on odds-ratios:**
			- If an odds-ratio is 1.0, then both events have an equal chance of occurring. For example, if the odds-ratio for a friend's recommendation was 1.0, then a friend would have no influence on a purchase decision.
			- If an odds-ratio is less than 1, then a friend's recommendation would decrease the chance of a purchase occurring. For example, an odds-ratio of 0.5 would mean a friend's recommendation has odds of 1:2 or 1 purchase occurring for every 2 passes.
			- If an odds-ratio is greater than 1, then a friend's recommendation would increase the chance of a purchase occurring. For example, an odds-ratio of 3.0 would mean a friend's recommendation has odds of 3:1 or 3 purchases occurring for every 1 passes.
			- ![[Pasted image 20231109160630.png|400]] 
- **count data**, we can also use *glmer() as an alternative to a Chi-square test*. Many introductory statistics courses cover the use of the *Chi-square test to compare count data*. Using a Poisson error term in a generalized linear model is an alternative. Broadly speaking, to use a Poisson error term instead of a Chi-square test, we estimate an intercept for each treatment group. We then can either examine each intercept estimate or use an ANOVA to examine if the terms are different than zero. We will go over this as an example during the exercises.
	- ![[Pasted image 20231109161104.png|400]] 
	- **Internet click-throughs**. A common theme throughout this course has been the nestedness of data. During this case study, you will examine the number of users who click through on a link to a website before and after a redesign. These users are nested within trial groups. You will then examine the outputs and make a recommendation to your client. For this redesign, you will examine the web behavior of 10 people from 4 different focus groups, for a total of 40 people. You want to know if the number of `clicks` to different pages changed from the old to the new `webpage` while correcting for `groups`.
		- ![[Pasted image 20231109161624.png|500]] ![[Pasted image 20231109161655.png|400]] 
	- **Chlamydia by age-group and county**. The number of infections change through time and vary across age groups. Some possible reasons cultural, social, and policy-related factors. For small populations, the number of infections often includes zeros and may be non-normal. For data such as these, use a Poisson model. This data comes from the State of Illinois who provides summaries of infections such as chlamydia by age groups and counties. First, fit a Poisson `glmer` to the data. Then, examine the results. In the next exercise, plot the data. **Warning:** If you mistype the formula, you may cause R to crash. This is a pitfall of using `lmer()` and `glmer()`.For this exercise, you will examine how [chlamydia infections](https://en.wikipedia.org/wiki/Chlamydia_infection) vary in small, Illinois counties. You will ask:
		1. Do the number of reported cases vary between people aged 15-19 compared to 20-24?
		2. Are the number of reported cases changing across time for these two age group?
		- ![[Pasted image 20231109161935.png|500]] ![[Pasted image 20231109162030.png|400]] ![[Pasted image 20231109162135.png|500]] ![[Pasted image 20231109162225.png|400]] ![[Pasted image 20231109162307.png|500]] 
# Repeated Measures and ANOVA and mixed model
- Often, we resample the same things over time. These study designs are called repeated measures and they are a special case of a mixed-effects model. During this section, I will show you how paired t-tests, repeated measures ANOVAs, and mixed-effect models are related. In the following sections of this chapter, we will see how to apply mixed-effects models to these situations. 
- To start off, what is a **repeated measure**? We might follow individuals through time, keep track of a football team over the course of a season, or visit the same forest sites repeatedly for an ecological study. These are repeated measures. These methods can be powerful because we can control for variability caused by individuals, teams, or sites. 
- A **paired t-test** is a special type of t-test that compares two observations to the same individual or samples. For example, we could look at student test scores pre- and post-intervention. The model is simple enough that it is a good introduction to repeated measures methods. Note that the elements of x1 and x2 should be the same length and correspond to the same individual. Otherwise, the model is the same as a plain t-test in R. One benefit to a repeated measures t-test is that it is more robust to violations of equal variance because it *does not assume equal variance for both groups*.
	- ![[Pasted image 20231109162610.png|300]] 
	- In the video, you learned how paired t-tests can be more powerful than regular t-tests. During this exercise, you will see an example demonstrating this. The first step will be to simulate data. Similar data might come from a people's weights before or after a drug treatment or amount of money spent by a customer before or after a seeing a commercial. *Simulated data allows you to know the properties of the data and check to see if your model behaves as expected*. R comes with many distributions including the [normal](https://www.rdocumentation.org/packages/stats/versions/3.5.2/topics/Normal). Your simulated data will have *unequal variance* (that is, the standard deviations will be different). The second step will be to analyze the data with both a paired and regular t-test. Last, you will be asked about the results from the paired t-tests. As part of the first step, you will "set the seed" for R's random number generator. This ensures you get the same numbers each time you run the code and DataCamp's software correctly scores your code.
		- ![[Pasted image 20231109163517.png|500]]  ![[Pasted image 20231109163646.png|400]] 
- Just as a t-test is a special case of an ANOVA, a paired t-test is a special case of a **repeated measures ANOVA**. This test examines *if means change across time*. In the paired t-test example, we examined scores from only two tests. With a repeated measures ANOVA, we can examine scores from multiple tests. For example, rather than looking at pre- and post-class test scores, we could look at test scores from the same group of students after multiple years of school. R does not include running a repeated measures ANOVA in base R. However, we can run an ANOVA on a lmer repeated measures model using the lmerTest package and get a repeated measures ANOVA. Hopefully, you have noticed from this slide how *a repeated-measures ANOVA is simply a special type of mixed-effects model*. As I just demonstrated, lmer() can be used for a repeated-measures ANOVA. However, *lmer() can be used to construct other repeated measure models as well*. All you need to do is include a time variable and a group variable. Hence, we are able to reuse a powerful tool in R that we have already learned. Also, I would add an important warning that different software, including different functions within R, may use different degrees of freedom with lmer models, which is something we will see in the exercises.
	- ![[Pasted image 20231109162907.png|300]] 
	- In the previous exercise, you saw how a paired t-test is more powerful than a regular t-test. During this exercise, you will see how statistical methods generalize. First, you will see how a paired t-test is a special case of a repeated measures ANOVA. In the process, you will see how a repeated measures ANOVA is a special case of a mixed-effects model by using `lmer()` in R. The first part of this exercise will consist of transforming the *simulated data from two vectors* into a `data.frame()`. The second part will have you examine the model results to see how they are different. The third part will have you examine the outputs of the models and compare the results.
		- ![[Pasted image 20231109164410.png|700]]
		- ![[Pasted image 20231109164341.png|300]] ![[Pasted image 20231109164941.png|500]] ![[Pasted image 20231109203312.png|500]] ![[Pasted image 20231109203903.png|500]] 
	- We will analyze the data using two different statistical approaches. Although we will use the same model, how we examine the results will be different. First, we will use an *ANOVA* type approach and examine if the drug impacts the amount of sleep. Specifically, we will examine if the drug covariate explains a significant amount of variability within the model. Our null hypothesis will be that the amount of sleep that study participants get does not differ as a result of the different treatments. Our alternative hypothesis will be that the drugs have different effects on the amount of sleep participants get. Second, we will use a *regression framework* for modeling. With a regression framework, we build a linear mixed model and then examine if the treatment coefficient differs from zero. This is the same model as the ANOVA, but rather than trying to explain variability, we examine if the one drug differs from another. A benefit of this approach is that we do not need to run a post-hoc test to see how the coefficient is different. A downside is that more complex regression models can be harder to understand than ANOVAs.
		- ![[Pasted image 20231109204205.png|400]] ![[Pasted image 20231109204221.png|300]] 
		- One of the first things to do with new datasets is to plot it prior to analysis. During this exercise, you will plot the data using `ggplot2` and create a publication quality figure. This will help you to _see_ the data. this data examines if two different drugs change the amount of sleep individuals get. The response variable of interest is the amount of `extra` sleep a patient gets. The predictor variable is the drug `group`. The `ID` of each patient allows us to do a repeated measures analysis. This is a random-effect intercept and corresponds to the baseline effect of giving a person a sleeping drug. We do not care how much an individuals sleeps in this case, only the change in sleep of the groups.
			- ![[Pasted image 20231109204424.png|500]]  ![[Pasted image 20231109204606.png|400]] 
			- ![[Pasted image 20231109204442.png|400]] ![[Pasted image 20231109204644.png|300]] 
		- In the previous exercise, you built a regression model. Two methods for statistical inference include examining the amount of variance explained by coefficients in the model (an _ANOVA_-like analysis) and using linear predictor variables to model the data (a _regression_ analysis framework). The choice of approaches largely depends upon personal preference and statistical training. Both of these approaches may be done using [frequentists](https://www.datacamp.com/courses/foundations-of-inference) or [Bayesian](https://www.datacamp.com/courses/fundamentals-of-bayesian-data-analysis-in-r) methods. Although this course only uses *frequentist methods*, the same ideas apply to Bayesian models. The `lmer_out` model you build in the previous exercise has been loaded for you. First, you will run an `anova()` on it to see if `group` explains a significant amount of variability. Second, you will examine the regression coefficient from `group` to see if it significantly differs from zero.
			- ![[Pasted image 20231109205230.png|500]] ![[Pasted image 20231109205300.png|500]] 
		- In the previous exercises, you have examined the raw data, used the data to build a model, and applied the model for statistical inferences. You found drug 2 increased the amount of extra sleep compared to drug 1. During this exercise, you will *plot the results* to see how much drug 2 increased extra sleep. First, wrangle the data by using `pivot_wider()` function from the `tidyr` package. Then, calculate the difference in extra sleep for each individual. Last, plot this difference as a histogram.
			- ![[Pasted image 20231109205906.png|400]] 
	- Exploring NY hate Data
		- ![[Pasted image 20231109211144.png|500]] ![[Pasted image 20231109211205.png|500]]
		- ![[Pasted image 20231109212139.png|600]] ![[Pasted image 20231109212225.png|600]] 
- ![[Pasted image 20231109212327.png|800]] 

 
